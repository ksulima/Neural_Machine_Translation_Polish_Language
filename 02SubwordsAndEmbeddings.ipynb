{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02SubwordsAndEmbeddings.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"PCysALY7MtWu","colab_type":"text"},"cell_type":"markdown","source":["#  Subwords and Embeddings\n","\n","This notebook contains the essence of the project. We will perform three things:<br>\n","\n","First we will use **Neural Machine Translation method** to segment text into **subword** units. <br>Then we will **train GloVe embeddings** on our dataset. <br>Finally we will use **Tensorboard** to visualize words transofrmed to vectors."]},{"metadata":{"id":"5W6nMEBQMsDP","colab_type":"text"},"cell_type":"markdown","source":["### Imports"]},{"metadata":{"id":"Y-zM09TTQutG","colab_type":"code","outputId":"43ddfb65-022b-4cc4-ec67-5f1804398629","executionInfo":{"status":"ok","timestamp":1552425832830,"user_tz":-60,"elapsed":6180,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"cell_type":"code","source":["!pip install subword-nmt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting subword-nmt\n","  Downloading https://files.pythonhosted.org/packages/26/08/58267cb3ac00f5f895457777ed9e0d106dbb5e6388fa7923d8663b04b849/subword_nmt-0.3.6-py2.py3-none-any.whl\n","Installing collected packages: subword-nmt\n","Successfully installed subword-nmt-0.3.6\n"],"name":"stdout"}]},{"metadata":{"id":"kBECQZBvMyYH","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","import sys, os\n","import collections\n","import nltk\n","import numpy as np\n","import pandas as pd\n","import re\n","import tempfile\n","import time\n","import subprocess\n","\n","\n","from google.colab import drive\n","from nltk.corpus import stopwords\n","from sklearn.externals import joblib\n","from subprocess import Popen, PIPE, check_call\n","from subword_nmt import apply_bpe\n","from subword_nmt.learn_joint_bpe_and_vocab import learn_joint_bpe_and_vocab\n","\n","\n","%reload_ext autoreload\n","%autoreload 2\n","\n","pd.set_option('display.max_colwidth', -1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DPdL7ecjRNTl","colab_type":"text"},"cell_type":"markdown","source":["### Colab setup"]},{"metadata":{"id":"_NNiZJCYNRev","colab_type":"code","outputId":"f1b0a731-0aed-4579-94d6-35240c31b120","executionInfo":{"status":"ok","timestamp":1552425835546,"user_tz":-60,"elapsed":467,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"HDrgNmjV-T9E","colab_type":"code","outputId":"8d8a7f9d-cff7-4c6c-975e-c2d8eb8569f1","executionInfo":{"status":"ok","timestamp":1552425836417,"user_tz":-60,"elapsed":534,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd ~/..\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/\n"],"name":"stdout"}]},{"metadata":{"id":"-_dH--xrJgkV","colab_type":"code","outputId":"7cf442d4-8cb8-4667-8dff-f1ef26133e17","executionInfo":{"status":"ok","timestamp":1552425839474,"user_tz":-60,"elapsed":459,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["os.getcwd()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/'"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"X1oVmmLBqCpd","colab_type":"text"},"cell_type":"markdown","source":["**Notice:** There is an issue related to whitespace in \"My Drive\" when trying to invoke path with it. As for now google colab does not allow to rename e.g. to \"MyDrive\". One walkaround is to create a symbolic link to omit problem with whitespace within \"My Drive\". "]},{"metadata":{"id":"Z0DBRyoAAh4_","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a symbolic link to omit issues with whitespace in \"My Drive\"\n","!ln -s ~/../content/gdrive/\"My Drive\"/ /MyDrive\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CosFWNwVsGYQ","colab_type":"text"},"cell_type":"markdown","source":["Remember to stay in current directory '/' to execute all cells successfully"]},{"metadata":{"id":"D4bm5RuQOcqL","colab_type":"code","colab":{}},"cell_type":"code","source":["PROJECT_HOME_PATH = os.path.join('MyDrive', 'NmtPolishLanguage')\n","DATA_PATH = os.path.join(PROJECT_HOME_PATH, 'DATA')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8Czik_FhmxJB","colab_type":"code","outputId":"869b4353-7599-4262-c07e-f1deb23b27f3","executionInfo":{"status":"ok","timestamp":1552425854353,"user_tz":-60,"elapsed":453,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["os.path.exists(PROJECT_HOME_PATH)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"eSLXv5iDSLLk","colab_type":"text"},"cell_type":"markdown","source":["### Load dataset"]},{"metadata":{"id":"RhJG4BpeOo3X","colab_type":"code","colab":{}},"cell_type":"code","source":["df_data = joblib.load(os.path.join(DATA_PATH, 'interim', 'hate_speach_mod.dat'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m9tHLg4FnrwF","colab_type":"code","outputId":"5ea54ada-d85d-403c-f806-e2ca2b37d88f","executionInfo":{"status":"ok","timestamp":1552425870197,"user_tz":-60,"elapsed":534,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"cell_type":"code","source":["df_data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>text_mod</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dla mnie faworytem do tytułu będzie Cracovia. Zobaczymy, czy typ się sprawdzi.</td>\n","      <td>faworytem do tytulu cracovia zobaczymy typ sprawdzi</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@anonymized_account @anonymized_account Brawo ty Daria kibic ma być na dobre i złe</td>\n","      <td>brawo daria kibic dobre zle</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@anonymized_account @anonymized_account Super, polski premier składa kwiaty na grobach kolaborantów. Ale doczekaliśmy czasów.</td>\n","      <td>super polski premier sklada kwiaty grobach kolaborantow doczekalismy czasow</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@anonymized_account @anonymized_account Musi. Innej drogi nie mamy.</td>\n","      <td>musi innej drogi nie mamy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Odrzut natychmiastowy, kwaśna mina, mam problem</td>\n","      <td>odrzut natychmiastowy kwasna mina problem</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                            text  \\\n","0  Dla mnie faworytem do tytułu będzie Cracovia. Zobaczymy, czy typ się sprawdzi.                                                  \n","1  @anonymized_account @anonymized_account Brawo ty Daria kibic ma być na dobre i złe                                              \n","2  @anonymized_account @anonymized_account Super, polski premier składa kwiaty na grobach kolaborantów. Ale doczekaliśmy czasów.   \n","3  @anonymized_account @anonymized_account Musi. Innej drogi nie mamy.                                                             \n","4  Odrzut natychmiastowy, kwaśna mina, mam problem                                                                                 \n","\n","                                                                      text_mod  \\\n","0  faworytem do tytulu cracovia zobaczymy typ sprawdzi                           \n","1  brawo daria kibic dobre zle                                                   \n","2  super polski premier sklada kwiaty grobach kolaborantow doczekalismy czasow   \n","3  musi innej drogi nie mamy                                                     \n","4  odrzut natychmiastowy kwasna mina problem                                     \n","\n","   target  \n","0  0       \n","1  0       \n","2  0       \n","3  0       \n","4  0       "]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"BHF12_M5mn1c","colab_type":"code","outputId":"3053a02a-7f10-4e82-966c-18ab74cae1d6","executionInfo":{"status":"ok","timestamp":1552425878728,"user_tz":-60,"elapsed":575,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["notes = df_data.text_mod\n","notes = list(notes)\n","\n","print(f'Number of notes: {len(notes)}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of notes: 10025\n"],"name":"stdout"}]},{"metadata":{"id":"asDd45nHmoDr","colab_type":"code","outputId":"d0b854fb-feb6-483a-90a8-1bc4983f682a","executionInfo":{"status":"ok","timestamp":1552425880748,"user_tz":-60,"elapsed":553,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"cell_type":"code","source":["notes[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['faworytem do tytulu cracovia zobaczymy typ sprawdzi',\n"," 'brawo daria kibic dobre zle',\n"," 'super polski premier sklada kwiaty grobach kolaborantow doczekalismy czasow',\n"," 'musi innej drogi nie mamy',\n"," 'odrzut natychmiastowy kwasna mina problem',\n"," 'fajny xdd pamietam spoznilam pierwsze zajecia sporo kare kazal usiasc pierwszej lawce xd',\n"," 'nie szczescia',\n"," 'dawno kogos wrednego nie widzialam xd',\n"," 'zaleglosci wazne wezwania do zaplaty klub nie wywiazal',\n"," 'brudzinski jestes klamca marnym kutasem']"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"FXuWOG7eXv-3","colab_type":"text"},"cell_type":"markdown","source":["### Words frequency"]},{"metadata":{"id":"aFgQMTz4WcvG","colab_type":"code","colab":{}},"cell_type":"code","source":["words_lst = [word.split(' ') for word in notes]\n","words_lst_flatten = [item for sublist in words_lst for item in sublist]\n","words_lst_flatten = pd.Series(words_lst_flatten)\n","vocab_count = words_lst_flatten.value_counts()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AP21BZTsXGqI","colab_type":"code","outputId":"b9fc6199-1c36-4831-e4fd-8d2bcda32482","executionInfo":{"status":"ok","timestamp":1552425885105,"user_tz":-60,"elapsed":563,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["vocab_count.head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["nie      3097\n","do       945 \n","rt       681 \n","od       365 \n","tez      336 \n","moze     309 \n","chyba    251 \n","sa       214 \n","wiem     176 \n","wiec     166 \n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"-ExdR4lqXCOr","colab_type":"code","outputId":"6223facd-1df9-4344-9166-7f2a622b4e57","executionInfo":{"status":"ok","timestamp":1552425887974,"user_tz":-60,"elapsed":546,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["print(f'Number of unique words in corpus: {len(vocab_count)}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of unique words in corpus: 21947\n"],"name":"stdout"}]},{"metadata":{"id":"of8YxLq1n1-i","colab_type":"text"},"cell_type":"markdown","source":["## Subword NMT"]},{"metadata":{"id":"VuMsICxMn-qn","colab_type":"text"},"cell_type":"markdown","source":["In this step we use *Subwords Neural Translation* method to generate subwords.\n","\n","If you wish to dive into details of this approach, here is the original paper: https://arxiv.org/abs/1508.07909\n","\n","Source code: https://github.com/rsennrich/subword-nmt\n","\n"]},{"metadata":{"id":"3A58euVCmoBP","colab_type":"code","colab":{}},"cell_type":"code","source":["Path = collections.namedtuple('Path', ['name'])\n","\n","\n","class LearnJointBpeVocabArgs:\n","    \"\"\"\n","    Helper for passing arguments to ``learn_joint_bpe_and_vocab``. This class\n","    needs to exists because logic in ``learn_joint_bpe_and_vocab.py`` is designed\n","    that way.\n","    \"\"\"  \n","    \n","    def __init__(self, input_, output, vocab, symbols=10000, min_frequency=5, verbose=False, separator='@@', total_symbols=5000):\n","      self.input=[Path(input_)]\n","      self.output = Path(output)\n","      self.vocab = [Path(vocab)]\n","      self.symbols = symbols\n","      self.min_frequency = min_frequency\n","      self.verbose = verbose\n","      self.separator = separator\n","      self.total_symbols = total_symbols\n","\n","        \n","def generate_subwords_vocab(notes, output_codes_path, output_vocab_path, symbols=10000, \n","                           min_frequency=5, verbose=False, separator='@@', total_symbols=5000):\n","  \n","    # temp file used here because learn_joint_bpe_and_vocab does not accept anything other than file\n","    with tempfile.NamedTemporaryFile('wt', encoding='utf-8', delete=False) as notes_temp_file:\n","        notes_temp_file.writelines(note + '\\n' for note in notes)\n","        notes_temp_file_path = notes_temp_file.name\n","        \n","        \n","    # this function automatically saves the result\n","    learn_joint_bpe_and_vocab(LearnJointBpeVocabArgs(\n","        input_ = notes_temp_file_path,\n","        output = output_codes_path,\n","        vocab = output_vocab_path,\n","        verbose = verbose,\n","        symbols = symbols,\n","        min_frequency = min_frequency,\n","        separator = separator,\n","        total_symbols = total_symbols\n","    ))\n","  \n","  \n","    os.remove(notes_temp_file_path)\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"23904c2Vdl0A","colab_type":"code","colab":{}},"cell_type":"code","source":["CODES_PATH = os.path.join(PROJECT_HOME_PATH, 'subwords', 'codes_10000_5_10000.txt')\n","VOCAB_PATH = os.path.join(PROJECT_HOME_PATH, 'subwords', 'vocab_10000_5_10000.txt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RndXTTRLdlrL","colab_type":"code","colab":{}},"cell_type":"code","source":["generate_subwords_vocab(\n","    notes=notes,\n","    output_codes_path = CODES_PATH,\n","    output_vocab_path = VOCAB_PATH,\n","    verbose=True,\n","    symbols=10000,\n","    min_frequency=5,\n","    total_symbols=10000\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dFiE6x_PaYRb","colab_type":"text"},"cell_type":"markdown","source":["Now we replace words in out **notes** with corresponding subwords and save them all as one text file called **corpus**. In a next step we use **corpus** to train glove embeddings."]},{"metadata":{"id":"4Z1mRJTEZ9vs","colab_type":"code","colab":{}},"cell_type":"code","source":["CORPUS_OUTPUT_PATH = os.path.join(DATA_PATH, 'glove', 'corpus_10000_5_10000.txt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FsxzcRzKZ92s","colab_type":"code","colab":{}},"cell_type":"code","source":["#minimum frequency of particular subword to be used.\n","vocab_threshold = 5\n","\n","with open(VOCAB_PATH, encoding='utf-8') as vocab_file:\n","    vocab = apply_bpe.read_vocabulary(vocab_file, threshold=vocab_threshold)\n","        \n","with open(CODES_PATH, encoding='utf-8') as codes_file:\n","    bpe = apply_bpe.BPE(codes_file, vocab=vocab)\n","    \n","with open(CORPUS_OUTPUT_PATH, mode='x', encoding='utf-8') as output_file:\n","  output_file.writelines(bpe.process_line(note) + '\\n' for note in notes)\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"-tg5CRTTeprl","colab_type":"text"},"cell_type":"markdown","source":["## Glove embeddings"]},{"metadata":{"id":"J-_Sb2ySZ-Ef","colab_type":"code","colab":{}},"cell_type":"code","source":["# If it happened that you don't need to use subwords to your problem, \n","# here are required steps to generate corpus and vocab when not using subwords.\n","\n","# You need to uncomment two following cells and execute them \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AKVKydfaZ-Ci","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","CORPUS_OUTPUT_PATH = os.path.join(DATA_PATH, 'glove', 'corpus.txt')\n","\n","with open(CORPUS_OUTPUT_PATH, mode='w', encoding='utf-8') as output_file:\n","    output_file.writelines(note + '\\n' for note in notes)\n","\n","\"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y3DnrUisZ96m","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","VOCAB_PATH = os.path.join(PROJECT_HOME_PATH, 'subwords', 'vocab.txt')\n","\n","# Number of most common words to be taken into consideration.\n","vocab_threshold = 20000\n","\n","words_lst = [word.split(' ') for word in notes]\n","words_lst_flatten = [item for sublist in words_lst for item in sublist]\n","words_lst_flatten = pd.Series(words_lst_flatten)\n","vocab = words_lst_flatten.value_counts()\n","\n","vocab[:vocab_threshold].to_csv(VOCAB_PATH, sep=' ', index=True, header=False)\n","\n","\"\"\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"HJEVjOzygdcB","colab_type":"text"},"cell_type":"markdown","source":["#### Download GloVe repository"]},{"metadata":{"id":"OvqFJVO7gaqd","colab_type":"code","outputId":"53cfb110-1aa8-4542-e33e-81c0731fd0a5","executionInfo":{"status":"ok","timestamp":1552426151406,"user_tz":-60,"elapsed":490,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["glove_repo_link = 'https://github.com/stanfordnlp/GloVe.git'\n","GLOVE_PATH = os.path.join(PROJECT_HOME_PATH, 'GloVe')\n","\n","\n","if not os.path.exists(GLOVE_PATH):\n","  print(f'Downloading GloVe project from the repository and placing under PROJECT_HOME_PATH: {glove_repo_link}')\n","  os.chdir(PROJECT_HOME_PATH)\n","  !git clone https://github.com/stanfordnlp/GloVe.git\n","  \n","else:\n","  print(f'GloVe project is already downloaded')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GloVe project is already downloaded\n"],"name":"stdout"}]},{"metadata":{"id":"tBZv1bUDIZYv","colab_type":"code","outputId":"5e181b81-f225-433a-a28d-76386c8dd230","executionInfo":{"status":"ok","timestamp":1552426153103,"user_tz":-60,"elapsed":637,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":[" cd ~/..\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"WrPF2kz2IY-z"},"cell_type":"markdown","source":["#### Execute make"]},{"metadata":{"id":"9Psgqi2Yga7e","colab_type":"code","colab":{}},"cell_type":"code","source":["def execute_script(file_path):\n","    p = Popen(['./{}'.format(file_path)], stdin=PIPE, stdout=PIPE, stderr=PIPE)\n","    output, err = p.communicate()\n","    rc = p.returncode\n","    return output, err"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","outputId":"5592ad4c-aa6f-432d-e9ed-3b6cff0ee9f0","executionInfo":{"status":"ok","timestamp":1552426163777,"user_tz":-60,"elapsed":4345,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"id":"Fdlcq0t6uPUV","colab":{"base_uri":"https://localhost:8080/","height":67}},"cell_type":"code","source":["# make GloVe\n","\n","if not os.path.exists(GLOVE_PATH):\n","    print(f'Please download GloVe project from the respository and place it under: {GLOVE_PATH}')\n","else:\n","    os.chdir(GLOVE_PATH)\n","    file_name = 'build_glove.sh'\n","    with open('./{}'.format(file_name), 'w') as file_handle:\n","        file_handle.write('#!/bin/bash\\n')\n","        file_handle.write('cd {}\\n'.format(GLOVE_PATH))\n","        file_handle.write('make\\n')\n","    os.chmod(file_name, 0o777)\n","    print('Executing make')\n","    output, err = execute_script('./{}'.format(file_name))\n","    print('./{}'.format(file_name))\n","    os.remove(file_name)\n"," \n","    print('Finished')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Executing make\n","./build_glove.sh\n","Finished\n"],"name":"stdout"}]},{"metadata":{"id":"un9ose3lIfX5","colab_type":"code","outputId":"73904a78-0f82-4de1-b030-dd46ca32473c","executionInfo":{"status":"ok","timestamp":1552426164518,"user_tz":-60,"elapsed":667,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd ~/.."],"execution_count":0,"outputs":[{"output_type":"stream","text":["/\n"],"name":"stdout"}]},{"metadata":{"id":"l9rSZnbRwNUK","colab_type":"code","colab":{}},"cell_type":"code","source":["GLOVE_BIN_PATH = os.path.join(PROJECT_HOME_PATH, 'GloVe', 'build')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OIrAv17qFvHa","colab_type":"code","outputId":"76bfc981-bfa1-4adb-8c21-851f80d9377b","executionInfo":{"status":"ok","timestamp":1552426168509,"user_tz":-60,"elapsed":1798,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"cell_type":"code","source":["ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mbin\u001b[0m/      \u001b[01;34mdatalab\u001b[0m/  \u001b[01;34mhome\u001b[0m/   \u001b[01;34mlib64\u001b[0m/  \u001b[01;36mMyDrive\u001b[0m@  \u001b[01;34mroot\u001b[0m/  \u001b[01;34msrv\u001b[0m/    \u001b[30;42mtmp\u001b[0m/    \u001b[01;34mvar\u001b[0m/\n","\u001b[01;34mboot\u001b[0m/     \u001b[01;34mdev\u001b[0m/      \u001b[01;34mlib\u001b[0m/    \u001b[01;34mmedia\u001b[0m/  \u001b[01;34mopt\u001b[0m/      \u001b[01;34mrun\u001b[0m/   \u001b[01;34mswift\u001b[0m/  \u001b[01;34mtools\u001b[0m/\n","\u001b[01;34mcontent\u001b[0m/  \u001b[01;34metc\u001b[0m/      \u001b[01;34mlib32\u001b[0m/  \u001b[01;34mmnt\u001b[0m/    \u001b[01;34mproc\u001b[0m/     \u001b[01;34msbin\u001b[0m/  \u001b[01;34msys\u001b[0m/    \u001b[01;34musr\u001b[0m/\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"nLFchcGBFuq3"},"cell_type":"markdown","source":["### Generate co-occurrence statistics"]},{"metadata":{"id":"ANCKDedukQWF","colab_type":"text"},"cell_type":"markdown","source":["The GloVe model is trained on the non-zero entries of a global word-word co-occurrence matrix, which tabulates how frequently words co-occur with one another in a given corpus. Populating this matrix requires a single pass through the entire corpus to collect the statistics. For large corpora, this pass can be computationally expensive, but it is a one-time up-front cost.\n","\n","The core training code is separated from these preprocessing steps and can be executed  independently."]},{"metadata":{"id":"bBB-N0spgbFQ","colab_type":"code","colab":{}},"cell_type":"code","source":["subwords_symbols = 10000\n","subwords_min_frequency = 5\n","glove_windows_size = 15\n","glove_iterations = 15\n","glove_vector_size = 50"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vI01sO9agbLV","colab_type":"code","colab":{}},"cell_type":"code","source":["subwords_params = str(subwords_symbols) + '_' + str(subwords_min_frequency)\n","cooccur_params = str(subwords_params) + '_' + str(glove_windows_size)\n","COOCCUR_PATH = os.path.join(DATA_PATH, 'glove', f'cooccurrence_{cooccur_params}')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"7ghkfBCzpjyP","colab":{}},"cell_type":"code","source":["def run_cooccur(vocab_path, corpus_path, cooccur_output_path, windows_size=15, verbose=False):\n","    \n","    if os.path.splitext(cooccur_output_path)[1]:\n","            raise ValueError(f'cooccur_output_path must not have any extension: {cooccur_output_path}')\n","    cooccur_output_path = cooccur_output_path + '.bin'\n","    cooccur_shuf_path = cooccur_output_path.replace('.bin', '.shuf.bin')\n","\n","    check_call(\n","              os.path.join(GLOVE_BIN_PATH, 'cooccur') +\n","              f' -vocab-file {vocab_path} -window-size {windows_size} -verbose {2 if verbose else 0}'\n","              f' < {corpus_path} > {cooccur_output_path}',\n","              shell=True\n","              )\n","\n","\n","    check_call(\n","              os.path.join(GLOVE_BIN_PATH, 'shuffle') +\n","              f' -verbose {2 if verbose else 0} < {cooccur_output_path} > {cooccur_shuf_path}',\n","              shell=True\n","              )    \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DV9e8QcdYgZP","colab_type":"code","colab":{}},"cell_type":"code","source":["#! MyDrive/NmtPolishLanguage/GloVe/build/cooccur -vocab-file MyDrive/NmtPolishLanguage/subwords/vocab_15000_5_15000.txt -window-size 15 -verbose 0 < MyDrive/NmtPolishLanguage/DATA/glove/corpus_15000_5_15000.txt > MyDrive/NmtPolishLanguage/DATA/glove/cooccurrence_15000_5_15.bin\n","#! MyDrive/NmtPolishLanguage/GloVe/build/shuffle -verbose 0 < MyDrive/NmtPolishLanguage/DATA/glove/cooccurrence_15000_5_15.bin > MyDrive/NmtPolishLanguage/DATA/glove/cooccurrence_15000_5_15.shuf.bin\n","\n","# subprocess.run('MyDrive/NmtPolishLanguage/GloVe/build/cooccur -vocab-file MyDrive/NmtPolishLanguage/subwords/vocab_15000_5_15000.txt -window-size 15 -verbose 0 < MyDrive/NmtPolishLanguage/DATA/glove/corpus_15000_5_15000.txt > MyDrive/NmtPolishLanguage/DATA/glove/cooccurrence_15000_5_15.bin', shell=True, check=True)\n","# subprocess.run('MyDrive/NmtPolishLanguage/GloVe/build/shuffle -verbose 0 < MyDrive/NmtPolishLanguage/DATA/glove/cooccurrence_15000_5_15.bin > MyDrive/NmtPolishLanguage/DATA/glove/cooccurrence_15000_5_15.shuf.bin',shell=True, check=True)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T65yxMHskfRO","colab_type":"code","colab":{}},"cell_type":"code","source":["run_cooccur(VOCAB_PATH, CORPUS_OUTPUT_PATH, COOCCUR_PATH, windows_size=glove_windows_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wyWdS9uipUod","colab_type":"text"},"cell_type":"markdown","source":["### Train GloVe embeddings"]},{"metadata":{"id":"fIEXN69BgbVs","colab_type":"code","colab":{}},"cell_type":"code","source":["glove_params = str(cooccur_params) + '_' + str(glove_iterations) + '_' + str(glove_vector_size)\n","VECTORS_PATH = os.path.join(DATA_PATH, 'glove', f'vectors_{glove_params}')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dh03R5QxgbPb","colab_type":"code","colab":{}},"cell_type":"code","source":["def run_glove(cooccur_path, vocab_path, vectors_output_path, vector_size=50, iterations=15,\n","             learning_rate=0.05, x_max=100, alpha=0.75, verbose=False, word2vec_format=False):\n","    if os.path.splitext(vectors_output_path)[1]:\n","        raise ValueError(f'vectors_output_path must not have any extansions: {vectors_output_path}')\n","        \n","    cooccur_path = cooccur_path + '.shuf.bin'\n","    threads = os.cpu_count()\n","    \n","    # glove automatically adds extension\n","    vectors_output_path = vectors_output_path.replace('.txt.', '')\n","    check_call(\n","        os.path.join(GLOVE_BIN_PATH, 'glove') +\n","        f' -input-file {cooccur_path} -vocab-file {vocab_path} -write-header {int(word2vec_format)}'\n","        f' -vector-size {vector_size} -iter {iterations} -eta {learning_rate} -x-max {x_max}'\n","        f' -alpha {alpha} -threads {threads} -save-file {vectors_output_path}'\n","        f' -verbose {2 if verbose else 0}',\n","        shell=True\n","    )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t3klbMq9gbJp","colab_type":"code","colab":{}},"cell_type":"code","source":["run_glove(COOCCUR_PATH, VOCAB_PATH, VECTORS_PATH, vector_size=glove_vector_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EV73O9taG6_W","colab_type":"text"},"cell_type":"markdown","source":["### Visualize embeddings in Tensorboard"]},{"metadata":{"id":"pWT8c6eKUmgP","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","from tensorboard import main as tb\n","from tensorflow.contrib.tensorboard.plugins import projector"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0L2cDSEiUmj0","colab_type":"code","colab":{}},"cell_type":"code","source":["VECTORS_FILE_PATH = VECTORS_PATH + '.txt'\n","words, embeddings = [], []\n","\n","with open(VECTORS_FILE_PATH, encoding='utf-8') as input_file:\n","    for line in input_file:\n","        word, *embedding = line.split()\n","        words.append(word)\n","        embeddings.append(np.array(embedding, dtype=float))\n","embeddings = np.array(embeddings)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X4HFIROYUmny","colab_type":"code","outputId":"749c27b0-69b1-4102-9500-702a87dbcc63","executionInfo":{"status":"ok","timestamp":1552224667871,"user_tz":-60,"elapsed":541,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["print(f'\\tembeddings shape: {embeddings.shape}\\n\\twords len: {len(words)}' )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\tembeddings shape: (6329, 50)\n","\twords len: 6329\n"],"name":"stdout"}]},{"metadata":{"id":"D0vUMD8WUmrh","colab_type":"code","colab":{}},"cell_type":"code","source":["TENSORBOARD_PATH = os.path.join(PROJECT_HOME_PATH, 'tensorboard')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"216yKOvXUmxt","colab_type":"code","colab":{}},"cell_type":"code","source":["def save_for_projector(vectors, tensorboard_output_path, metadata, name):\n","    metadata_output_path = os.path.join(tensorboard_output_path, 'metadata.tsv')\n","    model_checkpoint_path = os.path.join(tensorboard_output_path, 'model.ckpt')\n","    \n","    # if more than one column: first row must be deader row\n","    with open(metadata_output_path, 'w', encoding='utf-8') as output_file:\n","        output_file.writelines(word + '\\n' for word in metadata)\n","        \n","    session = tf.InteractiveSession()\n","    with tf.device(\"/cpu:0\"):\n","        vectors_var = tf.Variable(vectors, name=name, trainable=False)\n","        \n","    tf.global_variables_initializer().run()\n","    saver = tf.train.Saver()\n","    writer = tf.summary.FileWriter(tensorboard_output_path)\n","    config = projector.ProjectorConfig()\n","    config.model_checkpoint_path = model_checkpoint_path\n","    embedding = config.embeddings.add()\n","    embedding.tensor_name = vectors_var.name\n","    embedding.metadata_path = metadata_output_path\n","    projector.visualize_embeddings(writer, config)\n","    saver.save(session, model_checkpoint_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XI27Dn7fUm7C","colab_type":"code","outputId":"a4939e8a-cdca-4622-d947-60d8a49d35b4","executionInfo":{"status":"ok","timestamp":1552224706962,"user_tz":-60,"elapsed":658,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["len(words)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6329"]},"metadata":{"tags":[]},"execution_count":190}]},{"metadata":{"id":"6_s85fKZUnDH","colab_type":"code","outputId":"a566bea1-6742-47bf-fad8-692371bf46fd","executionInfo":{"status":"ok","timestamp":1552224709823,"user_tz":-60,"elapsed":2665,"user":{"displayName":"krzysiek s","photoUrl":"","userId":"11890224113498039296"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"cell_type":"code","source":["save_for_projector(embeddings, TENSORBOARD_PATH, words, name='embeddings')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"metadata":{"id":"qoef5CjtUnBf","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run tensorboard\n","\n","# In terminal:\n","#$tensorboard --logdir=TENSORBOARD_PATH --port=6009\n","\n","# If you run tensorboard on server, use port forwarding when log in: ssh [login@server] -L [port]:localhost:[port]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"alduke87Umvt","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}